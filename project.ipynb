{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 521153S Deep Learning Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.io import read_image\n",
    "from torchvision.models import resnet18, resnet34, resnet50, resnet101, resnet152, ResNet18_Weights, ResNet34_Weights, ResNet50_Weights, ResNet101_Weights, ResNet152_Weights, vgg11, vgg13, vgg16, vgg19, VGG11_Weights, VGG13_Weights, VGG16_Weights, VGG19_Weights\n",
    "import gdown\n",
    "import urllib\n",
    "import os\n",
    "import random\n",
    "import tarfile\n",
    "import time\n",
    "import shutil\n",
    "import logging as lg\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the logging level\n",
    "# Possible Levels: DEBUG, INFO,\n",
    "lg.basicConfig(level=lg.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# If you encounter some issues regarding cuda device, e.g., \"RuntimeError: CUDA Out of memory error\",\n",
    "# try to switch the device to cpu by using the following code\n",
    "\n",
    "# device = torch.device('cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Size\n",
    "image_size = 224\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "num_workers = 1\n",
    "\n",
    "# Learning rate for optimizers (id not good, decrease learning rate (try 0.001, 0.0001, 0.00001))\n",
    "lr = 0.001\n",
    "\n",
    "# Momentum\n",
    "momentum = 0.9\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Weight decay (if not good, increase weight_decay (try 1e-4, 1e-3, 1e-2))\n",
    "weight_decay=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): drive.google.com:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data directory\n",
      "Downloading val.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://drive.google.com:443 \"GET /u/0/uc?id=1hSMUMj5IRpf-nQs1OwgiQLmGZCN0KDWl HTTP/1.1\" 302 0\n",
      "DEBUG:urllib3.connectionpool:https://drive.google.com:443 \"GET /uc?id=1hSMUMj5IRpf-nQs1OwgiQLmGZCN0KDWl HTTP/1.1\" 303 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): doc-04-6o-docs.googleusercontent.com:443\n",
      "DEBUG:urllib3.connectionpool:https://doc-04-6o-docs.googleusercontent.com:443 \"GET /docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/s0jtnmhu824ud1pk4tv4m63dv9j78368/1703166525000/12865399289486813135/*/1hSMUMj5IRpf-nQs1OwgiQLmGZCN0KDWl?uuid=788df922-2bda-4a14-9eb7-26ccff04bd7a HTTP/1.1\" 200 30791680\n",
      "Downloading...\n",
      "From: https://drive.google.com/u/0/uc?id=1hSMUMj5IRpf-nQs1OwgiQLmGZCN0KDWl\n",
      "To: d:\\koodi\\Deep-Learning-Project\\data\\val.tar\n",
      "100%|██████████| 30.8M/30.8M [00:01<00:00, 18.9MB/s]\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): drive.google.com:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://drive.google.com:443 \"GET /u/0/uc?id=107FTosYIeBn5QbynR46YG91nHcJ70whs HTTP/1.1\" 302 0\n",
      "DEBUG:urllib3.connectionpool:https://drive.google.com:443 \"GET /uc?id=107FTosYIeBn5QbynR46YG91nHcJ70whs HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://drive.google.com:443 \"GET /uc?id=107FTosYIeBn5QbynR46YG91nHcJ70whs&confirm=t&uuid=57c652d0-28c4-45e9-a89a-a636a845eb5a HTTP/1.1\" 303 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): doc-0c-6o-docs.googleusercontent.com:443\n",
      "DEBUG:urllib3.connectionpool:https://doc-0c-6o-docs.googleusercontent.com:443 \"GET /docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/80eu5d9oibjg5teuhkiq2dcm67la05p2/1703166525000/12865399289486813135/*/107FTosYIeBn5QbynR46YG91nHcJ70whs?uuid=57c652d0-28c4-45e9-a89a-a636a845eb5a HTTP/1.1\" 200 125900800\n",
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/u/0/uc?id=107FTosYIeBn5QbynR46YG91nHcJ70whs\n",
      "From (redirected): https://drive.google.com/uc?id=107FTosYIeBn5QbynR46YG91nHcJ70whs&confirm=t&uuid=57c652d0-28c4-45e9-a89a-a636a845eb5a\n",
      "To: d:\\koodi\\Deep-Learning-Project\\data\\train.tar\n",
      "100%|██████████| 126M/126M [00:03<00:00, 34.1MB/s] \n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): drive.google.com:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading test.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://drive.google.com:443 \"GET /u/0/uc?id=1yKyKgxcnGMIAnA_6Vr2ilbpHMc9COg-v HTTP/1.1\" 302 0\n",
      "DEBUG:urllib3.connectionpool:https://drive.google.com:443 \"GET /uc?id=1yKyKgxcnGMIAnA_6Vr2ilbpHMc9COg-v HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://drive.google.com:443 \"GET /uc?id=1yKyKgxcnGMIAnA_6Vr2ilbpHMc9COg-v&confirm=t&uuid=9df87679-206c-4f02-8c82-f1f43dbce9e3 HTTP/1.1\" 303 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): doc-10-6o-docs.googleusercontent.com:443\n",
      "DEBUG:urllib3.connectionpool:https://doc-10-6o-docs.googleusercontent.com:443 \"GET /docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/q6ofjkm9fcq69cvf6ps5mv5chqqv5blm/1703166675000/12865399289486813135/*/1yKyKgxcnGMIAnA_6Vr2ilbpHMc9COg-v?uuid=9df87679-206c-4f02-8c82-f1f43dbce9e3 HTTP/1.1\" 200 39178240\n",
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/u/0/uc?id=1yKyKgxcnGMIAnA_6Vr2ilbpHMc9COg-v\n",
      "From (redirected): https://drive.google.com/uc?id=1yKyKgxcnGMIAnA_6Vr2ilbpHMc9COg-v&confirm=t&uuid=9df87679-206c-4f02-8c82-f1f43dbce9e3\n",
      "To: d:\\koodi\\Deep-Learning-Project\\data\\test.tar\n",
      "100%|██████████| 39.2M/39.2M [00:02<00:00, 17.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading EuroSAT_RGB.zip\n",
      "Downloading cub200_2011.tgz\n"
     ]
    }
   ],
   "source": [
    "# download the dataset\n",
    "val_url = 'https://drive.google.com/u/0/uc?id=1hSMUMj5IRpf-nQs1OwgiQLmGZCN0KDWl'\n",
    "train_url = 'https://drive.google.com/u/0/uc?id=107FTosYIeBn5QbynR46YG91nHcJ70whs'\n",
    "test_url = 'https://drive.google.com/u/0/uc?id=1yKyKgxcnGMIAnA_6Vr2ilbpHMc9COg-v'\n",
    "eurosat_url = 'https://zenodo.org/records/7711810/files/EuroSAT_RGB.zip?download=1'\n",
    "cub_url = 'https://data.caltech.edu/records/65de6-vp158/files/CUB_200_2011.tgz?download=1'\n",
    "\n",
    "val_file = './data/val.tar'\n",
    "train_file = './data/train.tar'\n",
    "test_file = './data/test.tar'\n",
    "eurosat_file = './data/eurosatrgb.zip'\n",
    "cub_file = './data/cub_200_2011.tgz'\n",
    "\n",
    "\n",
    "if not os.path.exists('./data'):\n",
    "    print('Creating data directory')\n",
    "    os.mkdir('./data')\n",
    "\n",
    "if not os.path.exists('./data/val.tar'):\n",
    "    print('Downloading val.tar')\n",
    "    gdown.download(val_url, val_file)\n",
    "    val_tar = tarfile.open(val_file)\n",
    "    val_tar.extractall('./data/')\n",
    "    val_tar.close()\n",
    "\n",
    "if not os.path.exists(train_file):\n",
    "    print('Downloading train.tar')\n",
    "    gdown.download(train_url, train_file)\n",
    "    train_tar = tarfile.open(train_file)\n",
    "    train_tar.extractall('./data/')\n",
    "    train_tar.close()\n",
    "\n",
    "if not os.path.exists(test_file):\n",
    "    print('Downloading test.tar')\n",
    "    gdown.download(test_url, test_file)\n",
    "    test_tar = tarfile.open(test_file)\n",
    "    test_tar.extractall('./data/')\n",
    "    test_tar.close()\n",
    "\n",
    "if not os.path.exists(eurosat_file):\n",
    "    print('Downloading EuroSAT_RGB.zip')\n",
    "    response = urllib.request.urlretrieve(eurosat_url, eurosat_file)\n",
    "    eurosat_zip = zipfile.ZipFile(eurosat_file)\n",
    "    eurosat_zip.extractall('./data/eurosat')\n",
    "    eurosat_zip.close()\n",
    "\n",
    "if not os.path.exists(cub_file):\n",
    "    print('Downloading cub200_2011.tgz')\n",
    "    response = urllib.request.urlretrieve(cub_url, cub_file)\n",
    "    tar = tarfile.open(cub_file, 'r')\n",
    "    for item in tar:\n",
    "        tar.extract(item, './data')\n",
    "    tar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\joona/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:01<00:00, 35.0MB/s]\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to C:\\Users\\joona/.cache\\torch\\hub\\checkpoints\\resnet34-b627a593.pth\n",
      "100%|██████████| 83.3M/83.3M [00:02<00:00, 36.5MB/s]\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\joona/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:02<00:00, 36.4MB/s]\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-cd907fc2.pth\" to C:\\Users\\joona/.cache\\torch\\hub\\checkpoints\\resnet101-cd907fc2.pth\n",
      "100%|██████████| 171M/171M [00:04<00:00, 35.9MB/s] \n",
      "Downloading: \"https://download.pytorch.org/models/resnet152-f82ba261.pth\" to C:\\Users\\joona/.cache\\torch\\hub\\checkpoints\\resnet152-f82ba261.pth\n",
      "100%|██████████| 230M/230M [00:06<00:00, 36.6MB/s] \n",
      "Downloading: \"https://download.pytorch.org/models/vgg11-8a719046.pth\" to C:\\Users\\joona/.cache\\torch\\hub\\checkpoints\\vgg11-8a719046.pth\n",
      "100%|██████████| 507M/507M [00:14<00:00, 36.5MB/s] \n",
      "Downloading: \"https://download.pytorch.org/models/vgg13-19584684.pth\" to C:\\Users\\joona/.cache\\torch\\hub\\checkpoints\\vgg13-19584684.pth\n",
      "100%|██████████| 508M/508M [00:14<00:00, 36.4MB/s] \n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\joona/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:15<00:00, 36.5MB/s] \n",
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to C:\\Users\\joona/.cache\\torch\\hub\\checkpoints\\vgg19-dcbb9e9d.pth\n",
      "100%|██████████| 548M/548M [00:15<00:00, 36.5MB/s] \n"
     ]
    }
   ],
   "source": [
    "model_resnet18 = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model_resnet34 = resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "model_resnet50 = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model_resnet101 = resnet101(weights=ResNet101_Weights.DEFAULT)\n",
    "model_resnet152 = resnet152(weights=ResNet152_Weights.DEFAULT)\n",
    "\n",
    "model_vgg11 = vgg11(weights=VGG11_Weights.DEFAULT)\n",
    "model_vgg13 = vgg13(weights=VGG13_Weights.DEFAULT)\n",
    "model_vgg16 = vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "model_vgg19 = vgg19(weights=VGG19_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root='./data/train',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), # mean and std for ImageNet dataset\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(\n",
    "    root='./data/test',\n",
    "    transform=transforms.Compose([\n",
    "        #transforms.Resize(image_size),\n",
    "        #transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    ")\n",
    "\n",
    "validation_dataset = torchvision.datasets.ImageFolder(\n",
    "    root='./data/val',\n",
    "    transform=transforms.Compose([\n",
    "        #transforms.Resize(image_size),\n",
    "        #transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "dataloader_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "dataloader_validation = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the training set: 26880\n",
      "Number of samples in the validation set: 5760\n",
      "Number of samples in the test set: 5760\n"
     ]
    }
   ],
   "source": [
    "# Stratified split, tries to maintain a proportional distribution of samples for each class in all three sets (train, val and test).\n",
    "\n",
    "# Val and Test ratio total, Train ratio (1-test_ratio)\n",
    "test_ratio = 0.3\n",
    "\n",
    "# Split between Val and Test\n",
    "test_val_split = 0.5\n",
    "\n",
    "# Loading the ImageFolder dataset\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='./data/train')\n",
    "\n",
    "# Getting the number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "# Initializing lists to store indices for train, validation, and test sets\n",
    "train_indices, val_indices, test_indices = [], [], []\n",
    "\n",
    "# Splitting each class separately\n",
    "for class_index in range(num_classes):\n",
    "    # Getting indices for samples belonging to the current class\n",
    "    class_indices = np.where(np.array(train_dataset.targets) == class_index)[0]\n",
    "    \n",
    "    # Splitting indices for each class separately into train, validation, and test sets\n",
    "    train_idx, temp_idx = train_test_split(class_indices, test_size=test_ratio, random_state=42)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=test_val_split, random_state=42)\n",
    "    \n",
    "    # Extending the lists to store indices for each set\n",
    "    train_indices.extend(train_idx)\n",
    "    val_indices.extend(val_idx)\n",
    "    test_indices.extend(test_idx)\n",
    "\n",
    "# Creating Subset objects using the selected indices for each set\n",
    "train_set = Subset(train_dataset, train_indices)\n",
    "val_set = Subset(train_dataset, val_indices)\n",
    "test_set = Subset(train_dataset, test_indices)\n",
    "\n",
    "# Transform functions\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(image_size),      \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), # mean and std for ImageNet dataset\n",
    "])\n",
    "\n",
    "transform_eval = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), # mean and std for ImageNet dataset\n",
    "])\n",
    "\n",
    "train_set.dataset.transform = transform_train\n",
    "val_set.dataset.transform = transform_eval\n",
    "test_set.dataset.transform = transform_eval\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Printing the sizes of the resulting sets\n",
    "print(f\"Number of samples in the training set: {len(train_set)}\")\n",
    "print(f\"Number of samples in the validation set: {len(val_set)}\")\n",
    "print(f\"Number of samples in the test set: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the used model\n",
    "model = model_resnet18\n",
    "model.name = \"resnet18\"     # Set name for saving\n",
    "\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device, criterion):\n",
    "\n",
    "    model.eval() \n",
    "    # valid_running_loss = 0.0\n",
    "    valid_running_correct = 0\n",
    "    counter = 0\n",
    "    num_images = 0.0 # used to accumulate number of images\n",
    "    \n",
    "    #with torch.no_grad():\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        counter += 1\n",
    "        \n",
    "        image, labels = data\n",
    "        image = image.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass.\n",
    "        outputs = model(image)\n",
    "        # Calculate the loss.\n",
    "        loss = criterion(outputs, labels)\n",
    "        # valid_running_loss += loss.item()\n",
    "        # Calculate the accuracy.\n",
    "        #preds = outputs.argmax(dim=1)\n",
    "        preds = torch.max(outputs, 1).indices\n",
    "        \n",
    "        #valid_running_correct += preds.eq(labels).sum()\n",
    "        valid_running_correct += torch.sum(preds == labels.data)\n",
    "        num_images += len(labels)\n",
    "        \n",
    "    # Loss and accuracy for the complete epoch.\n",
    "    # epoch_loss = valid_running_loss / counter\n",
    "    lg.debug(f\"EVAL:   loss.item(): {loss.item()} valid_running_correct: {valid_running_correct.item()}\")\n",
    "\n",
    "    epoch_acc = valid_running_correct / num_images\n",
    "    return epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainLoader, valLoader, criterion, optimizer, num_epochs, device):\n",
    "    model.to(device)\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "\n",
    "    # Start the training.\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using CUDA\")\n",
    "\n",
    "    print('Training')\n",
    "    \n",
    "    lg.debug(f\" len(trainLoader.dataset): {len(trainLoader.dataset)}\")\n",
    "    lg.debug(f\" len(valLoader.dataset): {len(valLoader.dataset)}\")\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_running_loss = 0.0\n",
    "        train_running_correct = 0\n",
    "        counter = 0\n",
    "        num_images = 0.0 # used to accumulate number of images\n",
    "        for i, data in enumerate(trainLoader,0):\n",
    "            counter += 1\n",
    "            image, labels = data\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass.\n",
    "            outputs = model(image)\n",
    "            # Calculate the loss.\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_running_loss += loss.item()\n",
    "            # Calculate the accuracy.\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            train_running_correct += torch.sum(preds == labels.data)\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            # Update the weights.\n",
    "            optimizer.step()    # Output training \n",
    "            num_images += len(image)\n",
    "            if counter % 100 == 0:\n",
    "                print(f'Epoch: {epoch+1}/{num_epochs}, Step: {counter}/{len(trainLoader)}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # reduce learning rate every 10 epochs by factor of 10\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] /= 10.0\n",
    "\n",
    "\n",
    "        # Validation\n",
    "        valid_epoch_acc = evaluate(model, valLoader, device, criterion)\n",
    "        lg.debug(f\"TRAIN: loss.item(): {loss.item()}, train_running_correct: {train_running_correct}\")\n",
    "        \n",
    "        # train_epoch_loss = train_running_loss / counter\n",
    "        # train_loss.append(train_epoch_loss)\n",
    "        # valid_loss.append(valid_epoch_loss)\n",
    "        train_epoch_acc = train_running_correct  / num_images\n",
    "        # train_acc.append(train_epoch_acc )\n",
    "\n",
    "        print('Epoch: %d/%d, Training accuracy: %f, Loss: %f, Validation accuracy: %f' % (epoch+1, num_epochs, train_epoch_acc, loss.item(), valid_epoch_acc))\n",
    "\n",
    "        # valid_acc.append(valid_epoch_acc)\n",
    "        # lg.debug(f\"Training loss mean: {train_epoch_loss :.3f}\")\n",
    "        # print(f\"Validation acc: {valid_epoch_acc:.3f}\")\n",
    "        print('-'*50)\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_model = train(model, dataloader_train, dataloader_validation, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root: len(trainLoader.dataset): 26880\n",
      "DEBUG:root: len(valLoader.dataset): 5760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Training\n",
      "Epoch: 1/10, Step: 100/210, Loss: 2.8659\n",
      "Epoch: 1/10, Step: 200/210, Loss: 1.6891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EVAL:   loss.item(): 2.3503589630126953 valid_running_correct: 4052\n",
      "DEBUG:root:TRAIN: loss.item(): 1.6037564277648926, train_running_correct: 11122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Training accuracy: 0.413765, Loss: 1.603756, Validation accuracy: 0.703472\n",
      "--------------------------------------------------\n",
      "Epoch: 2/10, Step: 100/210, Loss: 1.1886\n",
      "Epoch: 2/10, Step: 200/210, Loss: 1.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EVAL:   loss.item(): 1.3323090076446533 valid_running_correct: 4499\n",
      "DEBUG:root:TRAIN: loss.item(): 0.9654290080070496, train_running_correct: 20247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10, Training accuracy: 0.753237, Loss: 0.965429, Validation accuracy: 0.781076\n",
      "--------------------------------------------------\n",
      "Epoch: 3/10, Step: 100/210, Loss: 0.8426\n",
      "Epoch: 3/10, Step: 200/210, Loss: 0.5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EVAL:   loss.item(): 1.094102382659912 valid_running_correct: 4670\n",
      "DEBUG:root:TRAIN: loss.item(): 0.6858855485916138, train_running_correct: 21944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10, Training accuracy: 0.816369, Loss: 0.685886, Validation accuracy: 0.810764\n",
      "--------------------------------------------------\n",
      "Epoch: 4/10, Step: 100/210, Loss: 0.5271\n",
      "Epoch: 4/10, Step: 200/210, Loss: 0.5794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EVAL:   loss.item(): 1.0688108205795288 valid_running_correct: 4727\n",
      "DEBUG:root:TRAIN: loss.item(): 0.5832807421684265, train_running_correct: 22914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10, Training accuracy: 0.852455, Loss: 0.583281, Validation accuracy: 0.820660\n",
      "--------------------------------------------------\n",
      "Epoch: 5/10, Step: 100/210, Loss: 0.4938\n",
      "Epoch: 5/10, Step: 200/210, Loss: 0.4929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EVAL:   loss.item(): 0.9153974652290344 valid_running_correct: 4804\n",
      "DEBUG:root:TRAIN: loss.item(): 0.4758847951889038, train_running_correct: 23536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10, Training accuracy: 0.875595, Loss: 0.475885, Validation accuracy: 0.834028\n",
      "--------------------------------------------------\n",
      "Epoch: 6/10, Step: 100/210, Loss: 0.5624\n",
      "Epoch: 6/10, Step: 200/210, Loss: 0.3896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EVAL:   loss.item(): 0.8736052513122559 valid_running_correct: 4819\n",
      "DEBUG:root:TRAIN: loss.item(): 0.3337497413158417, train_running_correct: 24178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10, Training accuracy: 0.899479, Loss: 0.333750, Validation accuracy: 0.836632\n",
      "--------------------------------------------------\n",
      "Epoch: 7/10, Step: 100/210, Loss: 0.3515\n",
      "Epoch: 7/10, Step: 200/210, Loss: 0.3996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EVAL:   loss.item(): 0.8185217380523682 valid_running_correct: 4854\n",
      "DEBUG:root:TRAIN: loss.item(): 0.4369276165962219, train_running_correct: 24659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10, Training accuracy: 0.917374, Loss: 0.436928, Validation accuracy: 0.842708\n",
      "--------------------------------------------------\n",
      "Epoch: 8/10, Step: 100/210, Loss: 0.4127\n",
      "Epoch: 8/10, Step: 200/210, Loss: 0.3797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EVAL:   loss.item(): 0.7553919553756714 valid_running_correct: 4868\n",
      "DEBUG:root:TRAIN: loss.item(): 0.3855855464935303, train_running_correct: 25112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10, Training accuracy: 0.934226, Loss: 0.385586, Validation accuracy: 0.845139\n",
      "--------------------------------------------------\n",
      "Epoch: 9/10, Step: 100/210, Loss: 0.2560\n",
      "Epoch: 9/10, Step: 200/210, Loss: 0.2963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EVAL:   loss.item(): 0.7581312656402588 valid_running_correct: 4884\n",
      "DEBUG:root:TRAIN: loss.item(): 0.2746165096759796, train_running_correct: 25450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10, Training accuracy: 0.946801, Loss: 0.274617, Validation accuracy: 0.847917\n",
      "--------------------------------------------------\n",
      "Epoch: 10/10, Step: 100/210, Loss: 0.2354\n",
      "Epoch: 10/10, Step: 200/210, Loss: 0.2001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EVAL:   loss.item(): 0.7032350301742554 valid_running_correct: 4907\n",
      "DEBUG:root:TRAIN: loss.item(): 0.2885981500148773, train_running_correct: 25765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10, Training accuracy: 0.958519, Loss: 0.288598, Validation accuracy: 0.851910\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = train(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(trained_model):\n",
    "    # Create Models Folder\n",
    "    if not os.path.exists('./models'):\n",
    "        print('Creating models directory')\n",
    "        os.mkdir('./models')\n",
    "\n",
    "    # Save the model\n",
    "    if not os.path.exists(f'./models/{trained_model.name}.pth'):\n",
    "        print(f'Saving Model {trained_model.name}')\n",
    "        torch.save(trained_model, f'./models/{trained_model.name}.pth')\n",
    "\n",
    "def load_model(model_name):\n",
    "    if not os.path.exists(f'./models/{model_name}.pth'):\n",
    "        print(f'Cannot Load {model_name}')\n",
    "        return None\n",
    "    print(f'Loading Model {model_name}')\n",
    "    model = torch.load(f'./models/{model_name}.pth')\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EVAL:   loss.item(): 0.8170550465583801 valid_running_correct: 4870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.845\n"
     ]
    }
   ],
   "source": [
    "# validate_loss, validate_acc = evaluate(trained_model, dataloader_validation, criterion, device)\n",
    "# print(f\"Validation loss: {validate_loss:.3f}, validation acc: {validate_acc:.3f}\")\n",
    "test_acc = evaluate(pretrained_model, test_loader, device, criterion)\n",
    "print(f\"test acc: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_100_eurosat():\n",
    "    '''\n",
    "    The `choose_100_eurosat()` function selects 100 images from the EuroSAT dataset and copies them to the `data/eurosat_validation` folder. It also creates a `data/eurosat_training` folder if it doesn't already exist.\n",
    "    '''\n",
    "    if not os.path.exists('./data/eurosat_validation'):\n",
    "        print('Creating data directory')\n",
    "        os.mkdir('./data/eurosat_validation')\n",
    "    else:\n",
    "        # Folder full of images -> delete all files in the directory\n",
    "        shutil.rmtree(os.path.join('./data/eurosat_validation'))\n",
    "        os.mkdir('./data/eurosat_validation')\n",
    "\n",
    "    if not os.path.exists('./data/eurosat_training'):\n",
    "        print('Creating training directory')\n",
    "        os.mkdir('./data/eurosat_training')\n",
    "    else:\n",
    "        # Folder full of images -> delete all files in the directory\n",
    "        shutil.rmtree(os.path.join('./data/eurosat_training'))\n",
    "        os.mkdir('./data/eurosat_training')\n",
    "\n",
    "    # Load the EuroSAT Categories\n",
    "    eurosat_categories = [name for name in os.listdir('./data/eurosat/EuroSAT_RGB/') if os.path.isdir(os.path.join('./data/eurosat/EuroSAT_RGB/', name))]\n",
    "    # Randomly select 5 categories\n",
    "    lg.debug(f\"Selecting 5 categories from {eurosat_categories} categories\")\n",
    "    selected_categories = np.random.choice(eurosat_categories, 5, replace=False)\n",
    "    lg.debug(f\"Selected categories: {selected_categories}\")\n",
    "\n",
    "    selected_images = []\n",
    "    training_images = []\n",
    "\n",
    "    # From each directory, randomly select 20 images\n",
    "    for category in selected_categories:\n",
    "        images = os.listdir(os.path.join('./data/eurosat/EuroSAT_RGB/', category))\n",
    "        selected = random.sample(images, 20)\n",
    "        selected_images.extend([(category, image) for image in selected])\n",
    "        lg.debug(f\"Selected {selected} from {category}\")\n",
    "        # Copy selected images to the selected directory\n",
    "        for image in selected:\n",
    "            if not os.path.exists(f\"./data/eurosat_validation/{category}\"):\n",
    "                lg.debug(f\"Creating {category} directory\")\n",
    "                os.mkdir(f\"./data/eurosat_validation/{category}\")\n",
    "            shutil.copyfile(os.path.join('./data/eurosat/EuroSAT_RGB', category, image), os.path.join(f\"./data/eurosat_validation/{category}\", image))\n",
    "\n",
    "    # From these 100 images, randomly select 5 images from each category for the training set\n",
    "    for category in selected_categories:\n",
    "        category_images = [image for (cat, image) in selected_images if cat == category]\n",
    "        training = random.sample(category_images, 5)\n",
    "        training_images.extend(training)\n",
    "        lg.debug(f\"Selected {training} for training\")\n",
    "\n",
    "        # Copy training images to the training directory\n",
    "        for image in training:\n",
    "            if not os.path.exists(f\"./data/eurosat_training/{category}\"):\n",
    "                lg.debug(f\"Creating {category} directory\")\n",
    "                os.mkdir(f\"./data/eurosat_training/{category}\")\n",
    "            shutil.move(os.path.join(f\"./data/eurosat_validation/{category}\", image), os.path.join(f\"./data/eurosat_training/{category}\", image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_euro_datasets():\n",
    "\n",
    "    # Choose 100 images from EuroSAT dataset\n",
    "    choose_100_eurosat()\n",
    "\n",
    "    eurosat_train_dataset = torchvision.datasets.ImageFolder(\n",
    "        root='./data/eurosat_training',\n",
    "        transform=transforms.Compose([\n",
    "            transforms.RandomResizedCrop(image_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), # mean and std for ImageNet dataset\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    eurosat_validation_dataset = torchvision.datasets.ImageFolder(\n",
    "        root='./data/eurosat_validation',\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    eurosat_dataloader_train = DataLoader(eurosat_train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    eurosat_dataloader_validation = DataLoader(eurosat_validation_dataset, batch_size=batch_size, shuffle = False, num_workers=num_workers)\n",
    "\n",
    "    return eurosat_dataloader_train, eurosat_dataloader_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Selecting 5 categories from ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake'] categories\n",
      "DEBUG:root:Selected categories: ['AnnualCrop' 'HerbaceousVegetation' 'River' 'Pasture' 'SeaLake']\n",
      "DEBUG:root:Selected ['AnnualCrop_1605.jpg', 'AnnualCrop_1053.jpg', 'AnnualCrop_660.jpg', 'AnnualCrop_1947.jpg', 'AnnualCrop_1641.jpg', 'AnnualCrop_1819.jpg', 'AnnualCrop_1496.jpg', 'AnnualCrop_1078.jpg', 'AnnualCrop_2852.jpg', 'AnnualCrop_752.jpg', 'AnnualCrop_1607.jpg', 'AnnualCrop_923.jpg', 'AnnualCrop_1423.jpg', 'AnnualCrop_1763.jpg', 'AnnualCrop_42.jpg', 'AnnualCrop_72.jpg', 'AnnualCrop_2376.jpg', 'AnnualCrop_1154.jpg', 'AnnualCrop_2098.jpg', 'AnnualCrop_711.jpg'] from AnnualCrop\n",
      "DEBUG:root:Creating AnnualCrop directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model resnet18\n",
      "Creating data directory\n",
      "Creating training directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Selected ['HerbaceousVegetation_2155.jpg', 'HerbaceousVegetation_1073.jpg', 'HerbaceousVegetation_1248.jpg', 'HerbaceousVegetation_2167.jpg', 'HerbaceousVegetation_2884.jpg', 'HerbaceousVegetation_2454.jpg', 'HerbaceousVegetation_1998.jpg', 'HerbaceousVegetation_2582.jpg', 'HerbaceousVegetation_2528.jpg', 'HerbaceousVegetation_2567.jpg', 'HerbaceousVegetation_2104.jpg', 'HerbaceousVegetation_2685.jpg', 'HerbaceousVegetation_2548.jpg', 'HerbaceousVegetation_2618.jpg', 'HerbaceousVegetation_910.jpg', 'HerbaceousVegetation_1051.jpg', 'HerbaceousVegetation_1726.jpg', 'HerbaceousVegetation_1812.jpg', 'HerbaceousVegetation_1292.jpg', 'HerbaceousVegetation_2906.jpg'] from HerbaceousVegetation\n",
      "DEBUG:root:Creating HerbaceousVegetation directory\n",
      "DEBUG:root:Selected ['River_29.jpg', 'River_2173.jpg', 'River_1335.jpg', 'River_825.jpg', 'River_2479.jpg', 'River_1030.jpg', 'River_33.jpg', 'River_2232.jpg', 'River_1369.jpg', 'River_1653.jpg', 'River_2331.jpg', 'River_1140.jpg', 'River_1618.jpg', 'River_1851.jpg', 'River_1855.jpg', 'River_1978.jpg', 'River_301.jpg', 'River_1739.jpg', 'River_980.jpg', 'River_2129.jpg'] from River\n",
      "DEBUG:root:Creating River directory\n",
      "DEBUG:root:Selected ['Pasture_1877.jpg', 'Pasture_125.jpg', 'Pasture_867.jpg', 'Pasture_1386.jpg', 'Pasture_463.jpg', 'Pasture_1850.jpg', 'Pasture_1947.jpg', 'Pasture_291.jpg', 'Pasture_1522.jpg', 'Pasture_620.jpg', 'Pasture_355.jpg', 'Pasture_1699.jpg', 'Pasture_930.jpg', 'Pasture_1674.jpg', 'Pasture_583.jpg', 'Pasture_296.jpg', 'Pasture_1370.jpg', 'Pasture_548.jpg', 'Pasture_565.jpg', 'Pasture_1709.jpg'] from Pasture\n",
      "DEBUG:root:Creating Pasture directory\n",
      "DEBUG:root:Selected ['SeaLake_2310.jpg', 'SeaLake_2857.jpg', 'SeaLake_2609.jpg', 'SeaLake_2646.jpg', 'SeaLake_1345.jpg', 'SeaLake_1048.jpg', 'SeaLake_1673.jpg', 'SeaLake_2759.jpg', 'SeaLake_1351.jpg', 'SeaLake_1001.jpg', 'SeaLake_2294.jpg', 'SeaLake_1641.jpg', 'SeaLake_961.jpg', 'SeaLake_1913.jpg', 'SeaLake_1290.jpg', 'SeaLake_2219.jpg', 'SeaLake_1886.jpg', 'SeaLake_2098.jpg', 'SeaLake_1428.jpg', 'SeaLake_2841.jpg'] from SeaLake\n",
      "DEBUG:root:Creating SeaLake directory\n",
      "DEBUG:root:Selected ['AnnualCrop_2098.jpg', 'AnnualCrop_42.jpg', 'AnnualCrop_2376.jpg', 'AnnualCrop_660.jpg', 'AnnualCrop_1819.jpg'] for training\n",
      "DEBUG:root:Creating AnnualCrop directory\n",
      "DEBUG:root:Selected ['HerbaceousVegetation_2454.jpg', 'HerbaceousVegetation_2618.jpg', 'HerbaceousVegetation_2685.jpg', 'HerbaceousVegetation_1292.jpg', 'HerbaceousVegetation_2528.jpg'] for training\n",
      "DEBUG:root:Creating HerbaceousVegetation directory\n",
      "DEBUG:root:Selected ['River_1369.jpg', 'River_1030.jpg', 'River_1851.jpg', 'River_2479.jpg', 'River_1978.jpg'] for training\n",
      "DEBUG:root:Creating River directory\n",
      "DEBUG:root:Selected ['Pasture_565.jpg', 'Pasture_1522.jpg', 'Pasture_1699.jpg', 'Pasture_548.jpg', 'Pasture_296.jpg'] for training\n",
      "DEBUG:root:Creating Pasture directory\n",
      "DEBUG:root:Selected ['SeaLake_1913.jpg', 'SeaLake_1351.jpg', 'SeaLake_961.jpg', 'SeaLake_1001.jpg', 'SeaLake_1345.jpg'] for training\n",
      "DEBUG:root:Creating SeaLake directory\n",
      "DEBUG:root:Selecting 5 categories from ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake'] categories\n",
      "DEBUG:root:Selected categories: ['HerbaceousVegetation' 'AnnualCrop' 'PermanentCrop' 'Highway'\n",
      " 'Residential']\n",
      "DEBUG:root:Selected ['HerbaceousVegetation_993.jpg', 'HerbaceousVegetation_2438.jpg', 'HerbaceousVegetation_943.jpg', 'HerbaceousVegetation_55.jpg', 'HerbaceousVegetation_2375.jpg', 'HerbaceousVegetation_2288.jpg', 'HerbaceousVegetation_698.jpg', 'HerbaceousVegetation_917.jpg', 'HerbaceousVegetation_536.jpg', 'HerbaceousVegetation_2324.jpg', 'HerbaceousVegetation_2774.jpg', 'HerbaceousVegetation_1954.jpg', 'HerbaceousVegetation_238.jpg', 'HerbaceousVegetation_498.jpg', 'HerbaceousVegetation_287.jpg', 'HerbaceousVegetation_2184.jpg', 'HerbaceousVegetation_2840.jpg', 'HerbaceousVegetation_2859.jpg', 'HerbaceousVegetation_1407.jpg', 'HerbaceousVegetation_1960.jpg'] from HerbaceousVegetation\n",
      "DEBUG:root:Creating HerbaceousVegetation directory\n",
      "DEBUG:root:Selected ['AnnualCrop_1352.jpg', 'AnnualCrop_2981.jpg', 'AnnualCrop_129.jpg', 'AnnualCrop_2756.jpg', 'AnnualCrop_7.jpg', 'AnnualCrop_1874.jpg', 'AnnualCrop_837.jpg', 'AnnualCrop_2428.jpg', 'AnnualCrop_2003.jpg', 'AnnualCrop_2537.jpg', 'AnnualCrop_1428.jpg', 'AnnualCrop_2273.jpg', 'AnnualCrop_2102.jpg', 'AnnualCrop_2085.jpg', 'AnnualCrop_355.jpg', 'AnnualCrop_1648.jpg', 'AnnualCrop_1957.jpg', 'AnnualCrop_1195.jpg', 'AnnualCrop_937.jpg', 'AnnualCrop_563.jpg'] from AnnualCrop\n",
      "DEBUG:root:Creating AnnualCrop directory\n",
      "DEBUG:root:Selected ['PermanentCrop_767.jpg', 'PermanentCrop_781.jpg', 'PermanentCrop_2368.jpg', 'PermanentCrop_962.jpg', 'PermanentCrop_1146.jpg', 'PermanentCrop_1387.jpg', 'PermanentCrop_1200.jpg', 'PermanentCrop_2474.jpg', 'PermanentCrop_556.jpg', 'PermanentCrop_1920.jpg', 'PermanentCrop_756.jpg', 'PermanentCrop_2093.jpg', 'PermanentCrop_1436.jpg', 'PermanentCrop_937.jpg', 'PermanentCrop_481.jpg', 'PermanentCrop_1622.jpg', 'PermanentCrop_804.jpg', 'PermanentCrop_234.jpg', 'PermanentCrop_2199.jpg', 'PermanentCrop_254.jpg'] from PermanentCrop\n",
      "DEBUG:root:Creating PermanentCrop directory\n",
      "DEBUG:root:Selected ['Highway_1691.jpg', 'Highway_736.jpg', 'Highway_926.jpg', 'Highway_526.jpg', 'Highway_1147.jpg', 'Highway_72.jpg', 'Highway_6.jpg', 'Highway_237.jpg', 'Highway_1410.jpg', 'Highway_943.jpg', 'Highway_255.jpg', 'Highway_2209.jpg', 'Highway_1000.jpg', 'Highway_880.jpg', 'Highway_1587.jpg', 'Highway_1596.jpg', 'Highway_55.jpg', 'Highway_2068.jpg', 'Highway_1026.jpg', 'Highway_1261.jpg'] from Highway\n",
      "DEBUG:root:Creating Highway directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'results.txt' found and cleared.\n",
      "Training EuroSAT model 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Selected ['Residential_10.jpg', 'Residential_1467.jpg', 'Residential_257.jpg', 'Residential_1501.jpg', 'Residential_1265.jpg', 'Residential_2119.jpg', 'Residential_474.jpg', 'Residential_273.jpg', 'Residential_86.jpg', 'Residential_851.jpg', 'Residential_1402.jpg', 'Residential_300.jpg', 'Residential_1364.jpg', 'Residential_64.jpg', 'Residential_389.jpg', 'Residential_1293.jpg', 'Residential_2744.jpg', 'Residential_1295.jpg', 'Residential_166.jpg', 'Residential_263.jpg'] from Residential\n",
      "DEBUG:root:Creating Residential directory\n",
      "DEBUG:root:Selected ['HerbaceousVegetation_993.jpg', 'HerbaceousVegetation_1960.jpg', 'HerbaceousVegetation_2774.jpg', 'HerbaceousVegetation_55.jpg', 'HerbaceousVegetation_2288.jpg'] for training\n",
      "DEBUG:root:Creating HerbaceousVegetation directory\n",
      "DEBUG:root:Selected ['AnnualCrop_1648.jpg', 'AnnualCrop_1874.jpg', 'AnnualCrop_1352.jpg', 'AnnualCrop_7.jpg', 'AnnualCrop_355.jpg'] for training\n",
      "DEBUG:root:Creating AnnualCrop directory\n",
      "DEBUG:root:Selected ['PermanentCrop_254.jpg', 'PermanentCrop_756.jpg', 'PermanentCrop_804.jpg', 'PermanentCrop_1622.jpg', 'PermanentCrop_1436.jpg'] for training\n",
      "DEBUG:root:Creating PermanentCrop directory\n",
      "DEBUG:root:Selected ['Highway_1596.jpg', 'Highway_1587.jpg', 'Highway_926.jpg', 'Highway_943.jpg', 'Highway_255.jpg'] for training\n",
      "DEBUG:root:Creating Highway directory\n",
      "DEBUG:root:Selected ['Residential_300.jpg', 'Residential_257.jpg', 'Residential_263.jpg', 'Residential_273.jpg', 'Residential_1295.jpg'] for training\n",
      "DEBUG:root:Creating Residential directory\n",
      "DEBUG:root: len(trainLoader.dataset): 25\n",
      "DEBUG:root: len(valLoader.dataset): 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EVAL:   loss.item(): 2.304483652114868 valid_running_correct: 13\n",
      "DEBUG:root:TRAIN: loss.item(): 1.8782637119293213, train_running_correct: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30, Training accuracy: 0.240000, Loss: 1.878264, Validation accuracy: 0.173333\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EVAL:   loss.item(): 1.963905930519104 valid_running_correct: 12\n",
      "DEBUG:root:TRAIN: loss.item(): 1.948272466659546, train_running_correct: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/30, Training accuracy: 0.120000, Loss: 1.948272, Validation accuracy: 0.160000\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EVAL:   loss.item(): 1.4448789358139038 valid_running_correct: 15\n",
      "DEBUG:root:TRAIN: loss.item(): 2.7039904594421387, train_running_correct: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/30, Training accuracy: 0.240000, Loss: 2.703990, Validation accuracy: 0.200000\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EVAL:   loss.item(): 0.9625924229621887 valid_running_correct: 25\n",
      "DEBUG:root:TRAIN: loss.item(): 1.602229118347168, train_running_correct: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/30, Training accuracy: 0.280000, Loss: 1.602229, Validation accuracy: 0.333333\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EVAL:   loss.item(): 0.5640082359313965 valid_running_correct: 18\n",
      "DEBUG:root:TRAIN: loss.item(): 0.7296133041381836, train_running_correct: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/30, Training accuracy: 0.480000, Loss: 0.729613, Validation accuracy: 0.240000\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EVAL:   loss.item(): 0.5316546559333801 valid_running_correct: 20\n",
      "DEBUG:root:TRAIN: loss.item(): 1.9472284317016602, train_running_correct: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/30, Training accuracy: 0.280000, Loss: 1.947228, Validation accuracy: 0.266667\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained model\n",
    "model_resnet18_fine = load_model(\"resnet18\")\n",
    "\n",
    "for param in model_resnet18_fine.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_resnet18_fine.fc = nn.Linear(model_resnet18_fine.fc.in_features, 5)\n",
    "\n",
    "# Define loss function and optimizer for fine-tuning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_resnet18_fine.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "# Load the EuroSAT dataset\n",
    "eurosat_dataloader_train, eurosat_dataloader_validation = load_euro_datasets()\n",
    "\n",
    "if os.path.exists(\"results.txt\"):\n",
    "    # If the file exists, clear its contents\n",
    "    with open(\"results.txt\", \"w\") as f:\n",
    "        f.truncate(0)  # Clear the file content\n",
    "        print(\"File 'results.txt' found and cleared.\")\n",
    "\n",
    "# Train and Evaluate the model on the EuroSAT dataset\n",
    "i = 5\n",
    "average_results = 0.0\n",
    "\n",
    "for j in range(i):\n",
    "    print(f\"Training EuroSAT model {j+1}/{i}\")\n",
    "    eurosat_dataloader_train, eurosat_dataloader_validation = load_euro_datasets()\n",
    "    model_resnet18_fine = train(model_resnet18_fine, eurosat_dataloader_train, eurosat_dataloader_validation, criterion, optimizer, num_epochs, device)\n",
    "    results = evaluate(model_resnet18_fine, eurosat_dataloader_validation, device, criterion)\n",
    "    average_results += results\n",
    "    print(f\"EuroSAT model {j+1}/{i} results: {results:.3f}\")\n",
    "    # Save the results to results.txt\n",
    "    with open(\"results.txt\", \"a\") as f:\n",
    "        f.write(f\"{model_resnet18_fine.name} {j} Time: {time.strftime('%d/%m/%Y, %H:%M:%S')} Epochs: {num_epochs} | Results: {results:.6f}\\n\")\n",
    "        # f.close()\n",
    "\n",
    "average_results /= i\n",
    "print(f\"Average results: {average_results:.3f}\")\n",
    "with open(\"results.txt\", \"a\") as f:\n",
    "        f.write(f\"{model_resnet18_fine.name} Average results: {average_results:.6f}\\n\")\n",
    "        # f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate saved EuroSAT results average\n",
    "total_acc = 0\n",
    "count = 0\n",
    "\n",
    "# Open the file and read lines\n",
    "with open(\"results.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "    # Iterate through each line\n",
    "    for line in lines:\n",
    "        # Split the line to extract the accuracy value (assuming it's the 7th element when splitting by space)\n",
    "        line_parts = line.split()\n",
    "        if len(line_parts) >= 7:\n",
    "            results_acc = float(line_parts[6])  # Assuming accuracy is the 7th element\n",
    "            total_acc += results_acc\n",
    "            count += 1\n",
    "\n",
    "# Calculate the average accuracy\n",
    "if count > 0:\n",
    "    average_acc = total_acc / count\n",
    "    print(f\"Average results accuracy: {average_acc:.6f}\")\n",
    "else:\n",
    "    print(\"No accuracy values found in the file or the file is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESNET 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Size\n",
    "image_size = 224\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "num_workers = 1\n",
    "\n",
    "# Learning rate for optimizers (id not good, decrease learning rate (try 0.001, 0.0001, 0.00001))\n",
    "lr = 0.001\n",
    "\n",
    "# Momentum\n",
    "momentum = 0.9\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Weight decay (if not good, increase weight_decay (try 1e-4, 1e-3, 1e-2))\n",
    "weight_decay=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the used model\n",
    "model = model_resnet34\n",
    "model.name = \"resnet34\"     # Set name for saving\n",
    "\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = train(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate_loss, validate_acc = evaluate(trained_model, dataloader_validation, criterion, device)\n",
    "# print(f\"Validation loss: {validate_loss:.3f}, validation acc: {validate_acc:.3f}\")\n",
    "test_acc = evaluate(pretrained_model, test_loader, device, criterion)\n",
    "print(f\"test acc: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained model\n",
    "model_resnet34_fine = load_model(\"resnet34\")\n",
    "\n",
    "for param in model_resnet34_fine.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_resnet34_fine.fc = nn.Linear(model_resnet34_fine.fc.in_features, 5)\n",
    "\n",
    "# Define loss function and optimizer for fine-tuning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_resnet34_fine.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "# Load the EuroSAT dataset\n",
    "eurosat_dataloader_train, eurosat_dataloader_validation = load_euro_datasets()\n",
    "\n",
    "eurosat_trained_model = train(model_resnet34_fine, eurosat_dataloader_train, eurosat_dataloader_validation, criterion, optimizer, num_epochs, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 11\n",
    "\n",
    "for j in range(i):\n",
    "    print(f\"Training EuroSAT model {j+1}/{i}\")\n",
    "    eurosat_dataloader_train, eurosat_dataloader_validation = load_euro_datasets()\n",
    "    eurosat_trained_model = train(eurosat_trained_model, eurosat_dataloader_train, eurosat_dataloader_validation, criterion, optimizer, num_epochs, device)\n",
    "    results = evaluate(eurosat_trained_model, eurosat_dataloader_validation, device, criterion)\n",
    "    print(f\"EuroSAT model {j+1}/{i} results: {results:.3f}\")\n",
    "    # Save the results to results.txt\n",
    "    with open(\"results.txt\", \"a\") as f:\n",
    "        f.write(f\"{eurosat_trained_model.name} {j} Time: {time.strftime('%d/%m/%Y, %H:%M:%S')} Epochs: {num_epochs} | Results: {results:.6f}\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESNET 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Size\n",
    "image_size = 224\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "num_workers = 1\n",
    "\n",
    "# Learning rate for optimizers (id not good, decrease learning rate (try 0.001, 0.0001, 0.00001))\n",
    "lr = 0.001\n",
    "\n",
    "# Momentum\n",
    "momentum = 0.9\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Weight decay (if not good, increase weight_decay (try 1e-4, 1e-3, 1e-2))\n",
    "weight_decay=1e-2\n",
    "\n",
    "\n",
    "# Define the used model\n",
    "model = model_resnet50\n",
    "model.name = \"resnet50\"     # Set name for saving\n",
    "\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "pretrained_model = train(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(pretrained_model)\n",
    "\n",
    "# validate_loss, validate_acc = evaluate(trained_model, dataloader_validation, criterion, device)\n",
    "# print(f\"Validation loss: {validate_loss:.3f}, validation acc: {validate_acc:.3f}\")\n",
    "test_acc = evaluate(pretrained_model, test_loader, device, criterion)\n",
    "print(f\"test acc: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "\n",
    "\n",
    "# Load the pretrained model\n",
    "model_resnet50_fine = load_model(\"resnet50\")\n",
    "\n",
    "for param in model_resnet50_fine.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_resnet50_fine.fc = nn.Linear(model_resnet50_fine.fc.in_features, 5)\n",
    "\n",
    "# Define loss function and optimizer for fine-tuning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_resnet50_fine.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "# Load the EuroSAT dataset\n",
    "eurosat_dataloader_train, eurosat_dataloader_validation = load_euro_datasets()\n",
    "\n",
    "eurosat_trained_model = train(model_resnet50_fine, eurosat_dataloader_train, eurosat_dataloader_validation, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 11\n",
    "j = 1\n",
    "\n",
    "for j in range(i):\n",
    "    print(f\"Training EuroSAT model {j+1}/{i}\")\n",
    "    eurosat_dataloader_train, eurosat_dataloader_validation = load_euro_datasets()\n",
    "    eurosat_trained_model = train(eurosat_trained_model, eurosat_dataloader_train, eurosat_dataloader_validation, criterion, optimizer, num_epochs, device)\n",
    "    results = evaluate(eurosat_trained_model, eurosat_dataloader_validation, device, criterion)\n",
    "    print(f\"EuroSAT model {j+1}/{i} results: {results:.3f}\")\n",
    "    # Save the results to results.txt\n",
    "    with open(\"results.txt\", \"a\") as f:\n",
    "        f.write(f\"{j} Time: {time.strftime('%d/%m/%Y, %H:%M:%S')} Epochs: {num_epochs} | Results: {results:.6f}\\n\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET: CUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the validation set: 11788\n"
     ]
    }
   ],
   "source": [
    "cub_dataset = torchvision.datasets.ImageFolder(root='./data/CUB_200_2011/images')\n",
    "\n",
    "# Transform functions\n",
    "transform_eval = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), # mean and std for ImageNet dataset\n",
    "])\n",
    "\n",
    "cub_dataset.transform = transform_eval\n",
    "\n",
    "# Loading the ImageFolder dataset\n",
    "\n",
    "\n",
    "# Getting the number of classes\n",
    "cub_num_classes = len(cub_dataset.classes)\n",
    "\n",
    "cub_val_loader = DataLoader(cub_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "# Printing the sizes of the resulting sets\n",
    "print(f\"Number of samples in the validation set: {len(cub_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model resnet18\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Load the pretrained model\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m model_resnet18_fine \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet18\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model_resnet18_fine\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[0;32m     15\u001b[0m     param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[33], line 17\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model_name)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading Model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./models/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\joona\\.conda\\envs\\CUDA\\Lib\\site-packages\\torch\\serialization.py:1014\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1012\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1013\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1014\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1021\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1022\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joona\\.conda\\envs\\CUDA\\Lib\\site-packages\\torch\\serialization.py:1422\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1420\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1421\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1422\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1424\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1425\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[0;32m   1426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[0;32m   1427\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\joona\\.conda\\envs\\CUDA\\Lib\\site-packages\\torch\\serialization.py:1392\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1391\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1392\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\joona\\.conda\\envs\\CUDA\\Lib\\site-packages\\torch\\serialization.py:1366\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[0;32m   1363\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1364\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1365\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1366\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1367\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1368\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1371\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\joona\\.conda\\envs\\CUDA\\Lib\\site-packages\\torch\\serialization.py:381\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 381\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    383\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\joona\\.conda\\envs\\CUDA\\Lib\\site-packages\\torch\\serialization.py:279\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mUntypedStorage(obj\u001b[38;5;241m.\u001b[39mnbytes(), device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(location))\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joona\\.conda\\envs\\CUDA\\Lib\\site-packages\\torch\\_utils.py:117\u001b[0m, in \u001b[0;36m_cuda\u001b[1;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     untyped_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mUntypedStorage(\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize(), device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    116\u001b[0m     )\n\u001b[1;32m--> 117\u001b[0m     \u001b[43muntyped_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m untyped_storage\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Batch size during training\n",
    "num_workers = 1\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Weight decay (if not good, increase weight_decay (try 1e-4, 1e-3, 1e-2))\n",
    "weight_decay=1e-2\n",
    "\n",
    "\n",
    "# Load the pretrained model\n",
    "model_resnet18_fine = load_model(\"resnet18\")\n",
    "\n",
    "for param in model_resnet18_fine.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "model_resnet18_fine.fc = nn.Linear(model_resnet18_fine.fc.in_features, 5)\n",
    "\n",
    "# Define loss function and optimizer for fine-tuning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_resnet18_fine.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "model_resnet18_fine.to(device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA\")\n",
    "\n",
    "cub_model = evaluate(model_resnet18_fine, cub_val_loader, device, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
