{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 521153S Deep Learning Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.io import read_image\n",
    "from torchvision.models import resnet18, resnet34, resnet50, resnet101, resnet152, ResNet18_Weights, ResNet34_Weights, ResNet50_Weights, ResNet101_Weights, ResNet152_Weights, vgg11, vgg13, vgg16, vgg19, VGG11_Weights, VGG13_Weights, VGG16_Weights, VGG19_Weights\n",
    "import gdown\n",
    "import urllib\n",
    "import os\n",
    "import random\n",
    "import tarfile\n",
    "import time\n",
    "import shutil\n",
    "import logging as lg\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the logging level\n",
    "# Possible Levels: DEBUG, INFO,\n",
    "lg.basicConfig(level=lg.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset\n",
    "val_url = 'https://drive.google.com/u/0/uc?id=1hSMUMj5IRpf-nQs1OwgiQLmGZCN0KDWl'\n",
    "train_url = 'https://drive.google.com/u/0/uc?id=107FTosYIeBn5QbynR46YG91nHcJ70whs'\n",
    "test_url = 'https://drive.google.com/u/0/uc?id=1yKyKgxcnGMIAnA_6Vr2ilbpHMc9COg-v'\n",
    "eurosat_url = 'https://zenodo.org/records/7711810/files/EuroSAT_RGB.zip?download=1'\n",
    "\n",
    "val_file = './data/val.tar'\n",
    "train_file = './data/train.tar'\n",
    "test_file = './data/test.tar'\n",
    "eurosat_file = './data/eurosatrgb.zip'\n",
    "\n",
    "\n",
    "if not os.path.exists('./data'):\n",
    "    print('Creating data directory')\n",
    "    os.mkdir('./data')\n",
    "\n",
    "if not os.path.exists('./data/val.tar'):\n",
    "    print('Downloading val.tar')\n",
    "    gdown.download(val_url, val_file)\n",
    "    val_tar = tarfile.open(val_file)\n",
    "    val_tar.extractall('./data/')\n",
    "    val_tar.close()\n",
    "\n",
    "if not os.path.exists(train_file):\n",
    "    print('Downloading train.tar')\n",
    "    gdown.download(train_url, train_file)\n",
    "    train_tar = tarfile.open(train_file)\n",
    "    train_tar.extractall('./data/')\n",
    "    train_tar.close()\n",
    "\n",
    "if not os.path.exists(test_file):\n",
    "    print('Downloading test.tar')\n",
    "    gdown.download(test_url, test_file)\n",
    "    test_tar = tarfile.open(test_file)\n",
    "    test_tar.extractall('./data/')\n",
    "    test_tar.close()\n",
    "\n",
    "if not os.path.exists(eurosat_file):\n",
    "    print('Downloading EuroSAT_RGB.zip')\n",
    "    response = urllib.request.urlretrieve(eurosat_url, eurosat_file)\n",
    "    eurosat_zip = zipfile.ZipFile(eurosat_file)\n",
    "    eurosat_zip.extractall('./data/eurosat')\n",
    "    eurosat_zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# If you encounter some issues regarding cuda device, e.g., \"RuntimeError: CUDA Out of memory error\",\n",
    "# try to switch the device to cpu by using the following code\n",
    "\n",
    "# device = torch.device('cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Size\n",
    "image_size = 224\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "num_workers = 1\n",
    "\n",
    "# Learning rate for optimizers (id not good, decrease learning rate (try 0.001, 0.0001, 0.00001))\n",
    "lr = 0.001\n",
    "\n",
    "# Momentum\n",
    "momentum = 0.9\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Weight decay (if not good, increase weight_decay (try 1e-4, 1e-3, 1e-2))\n",
    "weight_decay=1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet18 = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model_resnet34 = resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "model_resnet50 = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model_resnet101 = resnet101(weights=ResNet101_Weights.DEFAULT)\n",
    "model_resnet152 = resnet152(weights=ResNet152_Weights.DEFAULT)\n",
    "\n",
    "model_vgg11 = vgg11(weights=VGG11_Weights.DEFAULT)\n",
    "model_vgg13 = vgg13(weights=VGG13_Weights.DEFAULT)\n",
    "model_vgg16 = vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "model_vgg19 = vgg19(weights=VGG19_Weights.DEFAULT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root='./data/train',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), # mean and std for ImageNet dataset\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(\n",
    "    root='./data/test',\n",
    "    transform=transforms.Compose([\n",
    "        #transforms.Resize(image_size),\n",
    "        #transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    ")\n",
    "\n",
    "validation_dataset = torchvision.datasets.ImageFolder(\n",
    "    root='./data/val',\n",
    "    transform=transforms.Compose([\n",
    "        #transforms.Resize(image_size),\n",
    "        #transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "dataloader_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "dataloader_validation = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the training set: 26880\n",
      "Number of samples in the validation set: 5760\n",
      "Number of samples in the test set: 5760\n"
     ]
    }
   ],
   "source": [
    "# Stratified split, tries to maintain a proportional distribution of samples for each class in all three sets (train, val and test).\n",
    "\n",
    "# Val and Test ratio total, Train ratio (1-test_ratio)\n",
    "test_ratio = 0.3\n",
    "\n",
    "# Split between Val and Test\n",
    "test_val_split = 0.5\n",
    "\n",
    "# Loading the ImageFolder dataset\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='./data/train')\n",
    "\n",
    "# Getting the number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "# Initializing lists to store indices for train, validation, and test sets\n",
    "train_indices, val_indices, test_indices = [], [], []\n",
    "\n",
    "# Splitting each class separately\n",
    "for class_index in range(num_classes):\n",
    "    # Getting indices for samples belonging to the current class\n",
    "    class_indices = np.where(np.array(train_dataset.targets) == class_index)[0]\n",
    "    \n",
    "    # Splitting indices for each class separately into train, validation, and test sets\n",
    "    train_idx, temp_idx = train_test_split(class_indices, test_size=test_ratio, random_state=42)\n",
    "    val_idx, test_idx = train_test_split(temp_idx, test_size=test_val_split, random_state=42)\n",
    "    \n",
    "    # Extending the lists to store indices for each set\n",
    "    train_indices.extend(train_idx)\n",
    "    val_indices.extend(val_idx)\n",
    "    test_indices.extend(test_idx)\n",
    "\n",
    "# Creating Subset objects using the selected indices for each set\n",
    "train_set = Subset(train_dataset, train_indices)\n",
    "val_set = Subset(train_dataset, val_indices)\n",
    "test_set = Subset(train_dataset, test_indices)\n",
    "\n",
    "# Transform functions\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),      \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), # mean and std for ImageNet dataset\n",
    "])\n",
    "\n",
    "transform_eval = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), # mean and std for ImageNet dataset\n",
    "])\n",
    "\n",
    "train_set.dataset.transform = transform_train\n",
    "val_set.dataset.transform = transform_eval\n",
    "test_set.dataset.transform = transform_eval\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Printing the sizes of the resulting sets\n",
    "print(f\"Number of samples in the training set: {len(train_set)}\")\n",
    "print(f\"Number of samples in the validation set: {len(val_set)}\")\n",
    "print(f\"Number of samples in the test set: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the used model\n",
    "model = model_resnet18\n",
    "model.name = \"resnet18\"     # Set name for saving\n",
    "\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(trained_model):\n",
    "    # Create Models Folder\n",
    "    if not os.path.exists('./models'):\n",
    "        print('Creating models directory')\n",
    "        os.mkdir('./models')\n",
    "\n",
    "    # Save the model\n",
    "    if not os.path.exists(f'./models/{trained_model.name}.pth'):\n",
    "        print(f'Saving Model {trained_model.name}')\n",
    "        torch.save(trained_model, f'./models/{trained_model.name}.pth')\n",
    "\n",
    "def load_model(model_name):\n",
    "    if not os.path.exists(f'./models/{model_name}.pth'):\n",
    "        print(f'Cannot Load {model_name}')\n",
    "        return None\n",
    "    print(f'Loading Model {model_name}')\n",
    "    model = torch.load(f'./models/{model_name}.pth')\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "\n",
    "    model.eval() \n",
    "    # valid_running_loss = 0.0\n",
    "    valid_running_correct = 0\n",
    "    counter = 0\n",
    "    num_images = 0.0 # used to accumulate number of images\n",
    "    \n",
    "    #with torch.no_grad():\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        counter += 1\n",
    "        \n",
    "        image, labels = data\n",
    "        image = image.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass.\n",
    "        outputs = model(image)\n",
    "        # Calculate the loss.\n",
    "        # loss = criterion(outputs, labels)\n",
    "        # valid_running_loss += loss.item()\n",
    "        # Calculate the accuracy.\n",
    "        #preds = outputs.argmax(dim=1)\n",
    "        preds = torch.max(outputs, 1).indices\n",
    "        \n",
    "        #valid_running_correct += preds.eq(labels).sum()\n",
    "        valid_running_correct += torch.sum(preds == labels.data)\n",
    "        num_images += len(labels)\n",
    "        \n",
    "    # Loss and accuracy for the complete epoch.\n",
    "    # epoch_loss = valid_running_loss / counter\n",
    "    lg.debug(f\"valid_running_correct: {valid_running_correct.item()}\")\n",
    "\n",
    "    epoch_acc = valid_running_correct / num_images\n",
    "    return epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainLoader, valLoader, criterion, optimizer, num_epochs, device):\n",
    "    model.to(device)\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "\n",
    "    # Start the training.\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using CUDA\")\n",
    "\n",
    "    print('Training')\n",
    "    \n",
    "    lg.debug(f\" len(trainLoader.dataset): {len(trainLoader.dataset)}\")\n",
    "    lg.debug(f\" len(valLoader.dataset): {len(valLoader.dataset)}\")\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_running_loss = 0.0\n",
    "        train_running_correct = 0\n",
    "        counter = 0\n",
    "        num_images = 0.0 # used to accumulate number of images\n",
    "        for i, data in enumerate(trainLoader,0):\n",
    "            counter += 1\n",
    "            image, labels = data\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass.\n",
    "            outputs = model(image)\n",
    "            # Calculate the loss.\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_running_loss += loss.item()\n",
    "            # Calculate the accuracy.\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            train_running_correct += torch.sum(preds == labels.data)\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            # Update the weights.\n",
    "            optimizer.step()    # Output training \n",
    "            num_images += len(image)\n",
    "            if counter % 100 == 0:\n",
    "                print(f'Epoch: {epoch+1}/{num_epochs}, Step: {counter}/{len(trainLoader)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "        # Validation\n",
    "        valid_epoch_acc = evaluate(model, valLoader, device)\n",
    "        lg.debug(f\"train_running_loss: {train_running_loss}, train_running_correct: {train_running_correct}\")\n",
    "        \n",
    "        # train_epoch_loss = train_running_loss / counter\n",
    "        # train_loss.append(train_epoch_loss)\n",
    "        # valid_loss.append(valid_epoch_loss)\n",
    "        train_epoch_acc = train_running_correct  / num_images\n",
    "        # train_acc.append(train_epoch_acc )\n",
    "\n",
    "        print('Epoch: %d/%d, Training accuracy: %f, Loss: %f, Validation accuracy: %f' % (epoch+1, num_epochs, train_epoch_acc, loss.item(), valid_epoch_acc))\n",
    "\n",
    "        # valid_acc.append(valid_epoch_acc)\n",
    "        # lg.debug(f\"Training loss mean: {train_epoch_loss :.3f}\")\n",
    "        # print(f\"Validation acc: {valid_epoch_acc:.3f}\")\n",
    "        print('-'*50)\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_model = train(model, dataloader_train, dataloader_validation, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root: len(trainLoader.dataset): 26880\n",
      "DEBUG:root: len(valLoader.dataset): 5760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Training\n",
      "Epoch: 1/10, Step: 100/210, Loss: 2.7449\n",
      "Epoch: 1/10, Step: 200/210, Loss: 1.6270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 4187\n",
      "DEBUG:root:train_running_loss: 585.4522787332535, train_running_correct: 12009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Training accuracy: 0.446763, Loss: 1.592140, Validation accuracy: 0.726910\n",
      "--------------------------------------------------\n",
      "Epoch: 2/10, Step: 100/210, Loss: 1.1672\n",
      "Epoch: 2/10, Step: 200/210, Loss: 1.0501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 4588\n",
      "DEBUG:root:train_running_loss: 243.0085175037384, train_running_correct: 20840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10, Training accuracy: 0.775298, Loss: 0.748118, Validation accuracy: 0.796528\n",
      "--------------------------------------------------\n",
      "Epoch: 3/10, Step: 100/210, Loss: 0.7811\n",
      "Epoch: 3/10, Step: 200/210, Loss: 0.6548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 4759\n",
      "DEBUG:root:train_running_loss: 162.90969216823578, train_running_correct: 22335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10, Training accuracy: 0.830915, Loss: 0.672509, Validation accuracy: 0.826215\n",
      "--------------------------------------------------\n",
      "Epoch: 4/10, Step: 100/210, Loss: 0.5774\n",
      "Epoch: 4/10, Step: 200/210, Loss: 0.7089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 4815\n",
      "DEBUG:root:train_running_loss: 127.77507469058037, train_running_correct: 23174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10, Training accuracy: 0.862128, Loss: 0.463221, Validation accuracy: 0.835938\n",
      "--------------------------------------------------\n",
      "Epoch: 5/10, Step: 100/210, Loss: 0.5503\n",
      "Epoch: 5/10, Step: 200/210, Loss: 0.6551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 4867\n",
      "DEBUG:root:train_running_loss: 105.02794793248177, train_running_correct: 23826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10, Training accuracy: 0.886384, Loss: 0.536573, Validation accuracy: 0.844965\n",
      "--------------------------------------------------\n",
      "Epoch: 6/10, Step: 100/210, Loss: 0.3796\n",
      "Epoch: 6/10, Step: 200/210, Loss: 0.3151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 4899\n",
      "DEBUG:root:train_running_loss: 87.71380865573883, train_running_correct: 24338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10, Training accuracy: 0.905432, Loss: 0.320375, Validation accuracy: 0.850521\n",
      "--------------------------------------------------\n",
      "Epoch: 7/10, Step: 100/210, Loss: 0.3029\n",
      "Epoch: 7/10, Step: 200/210, Loss: 0.3610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 4921\n",
      "DEBUG:root:train_running_loss: 74.36205834150314, train_running_correct: 24801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10, Training accuracy: 0.922656, Loss: 0.331149, Validation accuracy: 0.854340\n",
      "--------------------------------------------------\n",
      "Epoch: 8/10, Step: 100/210, Loss: 0.2637\n",
      "Epoch: 8/10, Step: 200/210, Loss: 0.2880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 4940\n",
      "DEBUG:root:train_running_loss: 63.21724930405617, train_running_correct: 25167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10, Training accuracy: 0.936272, Loss: 0.225380, Validation accuracy: 0.857639\n",
      "--------------------------------------------------\n",
      "Epoch: 9/10, Step: 100/210, Loss: 0.2248\n",
      "Epoch: 9/10, Step: 200/210, Loss: 0.2873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 4939\n",
      "DEBUG:root:train_running_loss: 53.526989713311195, train_running_correct: 25546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10, Training accuracy: 0.950372, Loss: 0.207097, Validation accuracy: 0.857465\n",
      "--------------------------------------------------\n",
      "Epoch: 10/10, Step: 100/210, Loss: 0.1863\n",
      "Epoch: 10/10, Step: 200/210, Loss: 0.2096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 4951\n",
      "DEBUG:root:train_running_loss: 45.61228997260332, train_running_correct: 25859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10, Training accuracy: 0.962016, Loss: 0.193105, Validation accuracy: 0.859549\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = train(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 4970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.863\n"
     ]
    }
   ],
   "source": [
    "# validate_loss, validate_acc = evaluate(trained_model, dataloader_validation, criterion, device)\n",
    "# print(f\"Validation loss: {validate_loss:.3f}, validation acc: {validate_acc:.3f}\")\n",
    "test_acc = evaluate(pretrained_model, test_loader, device)\n",
    "print(f\"test acc: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_100_eurosat():\n",
    "    '''\n",
    "    The `choose_100_eurosat()` function selects 100 images from the EuroSAT dataset and copies them to the `data/eurosat_validation` folder. It also creates a `data/eurosat_training` folder if it doesn't already exist.\n",
    "    '''\n",
    "    if not os.path.exists('./data/eurosat_validation'):\n",
    "        print('Creating data directory')\n",
    "        os.mkdir('./data/eurosat_validation')\n",
    "    else:\n",
    "        # Folder full of images -> delete all files in the directory\n",
    "        shutil.rmtree(os.path.join('./data/eurosat_validation'))\n",
    "        os.mkdir('./data/eurosat_validation')\n",
    "\n",
    "    if not os.path.exists('./data/eurosat_training'):\n",
    "        print('Creating training directory')\n",
    "        os.mkdir('./data/eurosat_training')\n",
    "    else:\n",
    "        # Folder full of images -> delete all files in the directory\n",
    "        shutil.rmtree(os.path.join('./data/eurosat_training'))\n",
    "        os.mkdir('./data/eurosat_training')\n",
    "\n",
    "    # Load the EuroSAT Categories\n",
    "    eurosat_categories = [name for name in os.listdir('./data/eurosat/EuroSAT_RGB/') if os.path.isdir(os.path.join('./data/eurosat/EuroSAT_RGB/', name))]\n",
    "    # Randomly select 5 categories\n",
    "    lg.debug(f\"Selecting 5 categories from {eurosat_categories} categories\")\n",
    "    selected_categories = np.random.choice(eurosat_categories, 5, replace=False)\n",
    "    lg.debug(f\"Selected categories: {selected_categories}\")\n",
    "\n",
    "    selected_images = []\n",
    "    training_images = []\n",
    "\n",
    "    # From each directory, randomly select 20 images\n",
    "    for category in selected_categories:\n",
    "        images = os.listdir(os.path.join('./data/eurosat/EuroSAT_RGB/', category))\n",
    "        selected = random.sample(images, 20)\n",
    "        selected_images.extend([(category, image) for image in selected])\n",
    "        lg.debug(f\"Selected {selected} from {category}\")\n",
    "        # Copy selected images to the selected directory\n",
    "        for image in selected:\n",
    "            if not os.path.exists(f\"./data/eurosat_validation/{category}\"):\n",
    "                lg.debug(f\"Creating {category} directory\")\n",
    "                os.mkdir(f\"./data/eurosat_validation/{category}\")\n",
    "            shutil.copyfile(os.path.join('./data/eurosat/EuroSAT_RGB', category, image), os.path.join(f\"./data/eurosat_validation/{category}\", image))\n",
    "\n",
    "    # From these 100 images, randomly select 5 images from each category for the training set\n",
    "    for category in selected_categories:\n",
    "        category_images = [image for (cat, image) in selected_images if cat == category]\n",
    "        training = random.sample(category_images, 5)\n",
    "        training_images.extend(training)\n",
    "        lg.debug(f\"Selected {training} for training\")\n",
    "\n",
    "        # Copy training images to the training directory\n",
    "        for image in training:\n",
    "            if not os.path.exists(f\"./data/eurosat_training/{category}\"):\n",
    "                lg.debug(f\"Creating {category} directory\")\n",
    "                os.mkdir(f\"./data/eurosat_training/{category}\")\n",
    "            shutil.move(os.path.join(f\"./data/eurosat_validation/{category}\", image), os.path.join(f\"./data/eurosat_training/{category}\", image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Selecting 5 categories from ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake'] categories\n",
      "DEBUG:root:Selected categories: ['River' 'Industrial' 'Forest' 'AnnualCrop' 'Residential']\n",
      "DEBUG:root:Selected ['River_999.jpg', 'River_1856.jpg', 'River_2178.jpg', 'River_171.jpg', 'River_645.jpg', 'River_9.jpg', 'River_1663.jpg', 'River_545.jpg', 'River_2462.jpg', 'River_950.jpg', 'River_505.jpg', 'River_1171.jpg', 'River_756.jpg', 'River_433.jpg', 'River_1945.jpg', 'River_442.jpg', 'River_239.jpg', 'River_1775.jpg', 'River_1290.jpg', 'River_1509.jpg'] from River\n",
      "DEBUG:root:Creating River directory\n",
      "DEBUG:root:Selected ['Industrial_1179.jpg', 'Industrial_1968.jpg', 'Industrial_1062.jpg', 'Industrial_643.jpg', 'Industrial_579.jpg', 'Industrial_365.jpg', 'Industrial_1413.jpg', 'Industrial_339.jpg', 'Industrial_1068.jpg', 'Industrial_1027.jpg', 'Industrial_2488.jpg', 'Industrial_2164.jpg', 'Industrial_2185.jpg', 'Industrial_2303.jpg', 'Industrial_169.jpg', 'Industrial_2157.jpg', 'Industrial_1936.jpg', 'Industrial_1010.jpg', 'Industrial_884.jpg', 'Industrial_600.jpg'] from Industrial\n",
      "DEBUG:root:Creating Industrial directory\n",
      "DEBUG:root:Selected ['Forest_1341.jpg', 'Forest_2722.jpg', 'Forest_1484.jpg', 'Forest_2559.jpg', 'Forest_1255.jpg', 'Forest_2845.jpg', 'Forest_239.jpg', 'Forest_107.jpg', 'Forest_1036.jpg', 'Forest_394.jpg', 'Forest_587.jpg', 'Forest_818.jpg', 'Forest_25.jpg', 'Forest_2596.jpg', 'Forest_1035.jpg', 'Forest_1724.jpg', 'Forest_2170.jpg', 'Forest_2308.jpg', 'Forest_531.jpg', 'Forest_759.jpg'] from Forest\n",
      "DEBUG:root:Creating Forest directory\n",
      "DEBUG:root:Selected ['AnnualCrop_1493.jpg', 'AnnualCrop_865.jpg', 'AnnualCrop_1789.jpg', 'AnnualCrop_2076.jpg', 'AnnualCrop_747.jpg', 'AnnualCrop_422.jpg', 'AnnualCrop_1006.jpg', 'AnnualCrop_1768.jpg', 'AnnualCrop_2724.jpg', 'AnnualCrop_822.jpg', 'AnnualCrop_2070.jpg', 'AnnualCrop_440.jpg', 'AnnualCrop_1450.jpg', 'AnnualCrop_1315.jpg', 'AnnualCrop_1936.jpg', 'AnnualCrop_633.jpg', 'AnnualCrop_153.jpg', 'AnnualCrop_876.jpg', 'AnnualCrop_2719.jpg', 'AnnualCrop_1104.jpg'] from AnnualCrop\n",
      "DEBUG:root:Creating AnnualCrop directory\n",
      "DEBUG:root:Selected ['Residential_2615.jpg', 'Residential_1878.jpg', 'Residential_1513.jpg', 'Residential_741.jpg', 'Residential_375.jpg', 'Residential_57.jpg', 'Residential_1492.jpg', 'Residential_2968.jpg', 'Residential_2866.jpg', 'Residential_1518.jpg', 'Residential_2403.jpg', 'Residential_1687.jpg', 'Residential_1519.jpg', 'Residential_1959.jpg', 'Residential_2744.jpg', 'Residential_2366.jpg', 'Residential_814.jpg', 'Residential_1063.jpg', 'Residential_1273.jpg', 'Residential_1919.jpg'] from Residential\n",
      "DEBUG:root:Creating Residential directory\n",
      "DEBUG:root:Selected ['River_756.jpg', 'River_999.jpg', 'River_950.jpg', 'River_1663.jpg', 'River_1171.jpg'] for training\n",
      "DEBUG:root:Creating River directory\n",
      "DEBUG:root:Selected ['Industrial_884.jpg', 'Industrial_1936.jpg', 'Industrial_579.jpg', 'Industrial_2488.jpg', 'Industrial_2157.jpg'] for training\n",
      "DEBUG:root:Creating Industrial directory\n",
      "DEBUG:root:Selected ['Forest_2559.jpg', 'Forest_1724.jpg', 'Forest_394.jpg', 'Forest_239.jpg', 'Forest_1035.jpg'] for training\n",
      "DEBUG:root:Creating Forest directory\n",
      "DEBUG:root:Selected ['AnnualCrop_633.jpg', 'AnnualCrop_2076.jpg', 'AnnualCrop_1789.jpg', 'AnnualCrop_1315.jpg', 'AnnualCrop_1104.jpg'] for training\n",
      "DEBUG:root:Creating AnnualCrop directory\n",
      "DEBUG:root:Selected ['Residential_375.jpg', 'Residential_1878.jpg', 'Residential_2968.jpg', 'Residential_1919.jpg', 'Residential_2615.jpg'] for training\n",
      "DEBUG:root:Creating Residential directory\n"
     ]
    }
   ],
   "source": [
    "# Choose 100 images from EuroSAT dataset\n",
    "choose_100_eurosat()\n",
    "\n",
    "\n",
    "eurosat_train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root='./data/eurosat_training',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomResizedCrop(image_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), # mean and std for ImageNet dataset\n",
    "    ])\n",
    ")\n",
    "\n",
    "eurosat_validation_dataset = torchvision.datasets.ImageFolder(\n",
    "    root='./data/eurosat_validation',\n",
    "    transform=transforms.Compose([\n",
    "        #transforms.Resize(256),\n",
    "        #transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    ")\n",
    "\n",
    "eurosat_dataloader_train = DataLoader(eurosat_train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "eurosat_dataloader_validation = DataLoader(eurosat_validation_dataset, batch_size=batch_size, shuffle = False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root: len(trainLoader.dataset): 25\n",
      "DEBUG:root: len(valLoader.dataset): 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model resnet18\n",
      "Using CUDA\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 1\n",
      "DEBUG:root:train_running_loss: 6.916092395782471, train_running_correct: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Training accuracy: 0.000000, Loss: 6.916092, Validation accuracy: 0.013333\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 1\n",
      "DEBUG:root:train_running_loss: 6.793035984039307, train_running_correct: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10, Training accuracy: 0.000000, Loss: 6.793036, Validation accuracy: 0.013333\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 0\n",
      "DEBUG:root:train_running_loss: 6.827473163604736, train_running_correct: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10, Training accuracy: 0.000000, Loss: 6.827473, Validation accuracy: 0.000000\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 0\n",
      "DEBUG:root:train_running_loss: 6.641732215881348, train_running_correct: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10, Training accuracy: 0.000000, Loss: 6.641732, Validation accuracy: 0.000000\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 0\n",
      "DEBUG:root:train_running_loss: 6.678532123565674, train_running_correct: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10, Training accuracy: 0.000000, Loss: 6.678532, Validation accuracy: 0.000000\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 0\n",
      "DEBUG:root:train_running_loss: 7.014364242553711, train_running_correct: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10, Training accuracy: 0.000000, Loss: 7.014364, Validation accuracy: 0.000000\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 0\n",
      "DEBUG:root:train_running_loss: 6.588929653167725, train_running_correct: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10, Training accuracy: 0.000000, Loss: 6.588930, Validation accuracy: 0.000000\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 0\n",
      "DEBUG:root:train_running_loss: 6.510319709777832, train_running_correct: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10, Training accuracy: 0.040000, Loss: 6.510320, Validation accuracy: 0.000000\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 0\n",
      "DEBUG:root:train_running_loss: 6.671468734741211, train_running_correct: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10, Training accuracy: 0.040000, Loss: 6.671469, Validation accuracy: 0.000000\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:valid_running_correct: 0\n",
      "DEBUG:root:train_running_loss: 6.399109363555908, train_running_correct: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10, Training accuracy: 0.040000, Loss: 6.399109, Validation accuracy: 0.000000\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained model\n",
    "model_resnet18_fine = load_model(\"resnet18\")\n",
    "\n",
    "# Define loss function and optimizer for fine-tuning\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "eurosat_trained_model = train(model_resnet18_fine, eurosat_dataloader_train, eurosat_dataloader_validation, criterion, optimizer, num_epochs, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
