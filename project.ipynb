{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 521153S Deep Learning Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.io import read_image\n",
    "from torchvision.models import resnet18, resnet34, resnet50, resnet101, resnet152, ResNet18_Weights, ResNet34_Weights, ResNet50_Weights, ResNet101_Weights, ResNet152_Weights, vgg11, vgg13, vgg16, vgg19, VGG11_Weights, VGG13_Weights, VGG16_Weights, VGG19_Weights\n",
    "import gdown\n",
    "import urllib\n",
    "import os\n",
    "import random\n",
    "import tarfile\n",
    "import time\n",
    "import shutil\n",
    "import logging as lg\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the logging level\n",
    "# Possible Levels: DEBUG, INFO,\n",
    "lg.basicConfig(level=lg.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): drive.google.com:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data directory\n",
      "Downloading val.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://drive.google.com:443 \"GET /u/0/uc?id=1hSMUMj5IRpf-nQs1OwgiQLmGZCN0KDWl HTTP/1.1\" 302 0\n",
      "DEBUG:urllib3.connectionpool:https://drive.google.com:443 \"GET /uc?id=1hSMUMj5IRpf-nQs1OwgiQLmGZCN0KDWl HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://drive.google.com:443 \"GET /uc?id=1hSMUMj5IRpf-nQs1OwgiQLmGZCN0KDWl&confirm=t&uuid=c0b0f627-c14b-4488-9be4-5aecaadb2dcf HTTP/1.1\" 303 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): doc-00-3g-docs.googleusercontent.com:443\n",
      "DEBUG:urllib3.connectionpool:https://doc-00-3g-docs.googleusercontent.com:443 \"GET /docs/securesc/0kmt8bdmqm98llfgnreft9bpc75s23vp/3g2uarrf6gmeaaa9qocipvmivu09rtg2/1702652175000/12865399289486813135/14485584017585893037Z/1hSMUMj5IRpf-nQs1OwgiQLmGZCN0KDWl?uuid=c0b0f627-c14b-4488-9be4-5aecaadb2dcf HTTP/1.1\" 302 0\n",
      "DEBUG:urllib3.connectionpool:https://drive.google.com:443 \"GET /nonceSigner?nonce=8u91kof0vjoqg&continue=https://doc-00-3g-docs.googleusercontent.com/docs/securesc/0kmt8bdmqm98llfgnreft9bpc75s23vp/3g2uarrf6gmeaaa9qocipvmivu09rtg2/1702652175000/12865399289486813135/14485584017585893037Z/1hSMUMj5IRpf-nQs1OwgiQLmGZCN0KDWl?uuid%3Dc0b0f627-c14b-4488-9be4-5aecaadb2dcf&hash=b00iitrql4kka15vikbeg58pvcm6mreb HTTP/1.1\" 302 0\n",
      "DEBUG:urllib3.connectionpool:https://doc-00-3g-docs.googleusercontent.com:443 \"GET /docs/securesc/0kmt8bdmqm98llfgnreft9bpc75s23vp/3g2uarrf6gmeaaa9qocipvmivu09rtg2/1702652175000/12865399289486813135/14485584017585893037Z/1hSMUMj5IRpf-nQs1OwgiQLmGZCN0KDWl?uuid=c0b0f627-c14b-4488-9be4-5aecaadb2dcf&nonce=8u91kof0vjoqg&user=14485584017585893037Z&hash=qebjcpm79i7au4ki8g37iee46fvmubvj HTTP/1.1\" 200 30791680\n",
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/u/0/uc?id=1hSMUMj5IRpf-nQs1OwgiQLmGZCN0KDWl\n",
      "From (redirected): https://drive.google.com/uc?id=1hSMUMj5IRpf-nQs1OwgiQLmGZCN0KDWl&confirm=t&uuid=c0b0f627-c14b-4488-9be4-5aecaadb2dcf\n",
      "To: d:\\Koodi\\Deep-Learning-Project\\data\\val.tar\n",
      "100%|██████████| 30.8M/30.8M [00:02<00:00, 11.1MB/s]\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): drive.google.com:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://drive.google.com:443 \"GET /u/0/uc?id=107FTosYIeBn5QbynR46YG91nHcJ70whs HTTP/1.1\" 302 0\n",
      "DEBUG:urllib3.connectionpool:https://drive.google.com:443 \"GET /uc?id=107FTosYIeBn5QbynR46YG91nHcJ70whs HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://drive.google.com:443 \"GET /uc?id=107FTosYIeBn5QbynR46YG91nHcJ70whs&confirm=t&uuid=9d4124c8-dd39-4886-9911-8f23bed5eff2 HTTP/1.1\" 303 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): doc-0g-3g-docs.googleusercontent.com:443\n",
      "DEBUG:urllib3.connectionpool:https://doc-0g-3g-docs.googleusercontent.com:443 \"GET /docs/securesc/0kmt8bdmqm98llfgnreft9bpc75s23vp/5oht94nk6avr0h99bost51bvncbsb1t4/1702652175000/12865399289486813135/14485584017585893037Z/107FTosYIeBn5QbynR46YG91nHcJ70whs?uuid=9d4124c8-dd39-4886-9911-8f23bed5eff2 HTTP/1.1\" 200 125900800\n",
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/u/0/uc?id=107FTosYIeBn5QbynR46YG91nHcJ70whs\n",
      "From (redirected): https://drive.google.com/uc?id=107FTosYIeBn5QbynR46YG91nHcJ70whs&confirm=t&uuid=9d4124c8-dd39-4886-9911-8f23bed5eff2\n",
      "To: d:\\Koodi\\Deep-Learning-Project\\data\\train.tar\n",
      "100%|██████████| 126M/126M [00:11<00:00, 11.4MB/s] \n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): drive.google.com:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading test.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://drive.google.com:443 \"GET /u/0/uc?id=1yKyKgxcnGMIAnA_6Vr2ilbpHMc9COg-v HTTP/1.1\" 302 0\n",
      "DEBUG:urllib3.connectionpool:https://drive.google.com:443 \"GET /uc?id=1yKyKgxcnGMIAnA_6Vr2ilbpHMc9COg-v HTTP/1.1\" 303 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): doc-10-3g-docs.googleusercontent.com:443\n",
      "DEBUG:urllib3.connectionpool:https://doc-10-3g-docs.googleusercontent.com:443 \"GET /docs/securesc/0kmt8bdmqm98llfgnreft9bpc75s23vp/m2o9lra63ak58osgc0j9d35flgpffvf9/1702652175000/12865399289486813135/14485584017585893037Z/1yKyKgxcnGMIAnA_6Vr2ilbpHMc9COg-v?uuid=45ea8466-3916-4123-8970-a83e92985639 HTTP/1.1\" 200 39178240\n",
      "Downloading...\n",
      "From: https://drive.google.com/u/0/uc?id=1yKyKgxcnGMIAnA_6Vr2ilbpHMc9COg-v\n",
      "To: d:\\Koodi\\Deep-Learning-Project\\data\\test.tar\n",
      "100%|██████████| 39.2M/39.2M [00:03<00:00, 11.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading EuroSAT_RGB.zip\n"
     ]
    }
   ],
   "source": [
    "# download the dataset\n",
    "val_url = 'https://drive.google.com/u/0/uc?id=1hSMUMj5IRpf-nQs1OwgiQLmGZCN0KDWl'\n",
    "train_url = 'https://drive.google.com/u/0/uc?id=107FTosYIeBn5QbynR46YG91nHcJ70whs'\n",
    "test_url = 'https://drive.google.com/u/0/uc?id=1yKyKgxcnGMIAnA_6Vr2ilbpHMc9COg-v'\n",
    "eurosat_url = 'https://zenodo.org/records/7711810/files/EuroSAT_RGB.zip?download=1'\n",
    "\n",
    "val_file = './data/val.tar'\n",
    "train_file = './data/train.tar'\n",
    "test_file = './data/test.tar'\n",
    "eurosat_file = './data/eurosatrgb.zip'\n",
    "\n",
    "\n",
    "if not os.path.exists('./data'):\n",
    "    print('Creating data directory')\n",
    "    os.mkdir('./data')\n",
    "\n",
    "if not os.path.exists('./data/val.tar'):\n",
    "    print('Downloading val.tar')\n",
    "    gdown.download(val_url, val_file)\n",
    "    val_tar = tarfile.open(val_file)\n",
    "    val_tar.extractall('./data/')\n",
    "    val_tar.close()\n",
    "\n",
    "if not os.path.exists(train_file):\n",
    "    print('Downloading train.tar')\n",
    "    gdown.download(train_url, train_file)\n",
    "    train_tar = tarfile.open(train_file)\n",
    "    train_tar.extractall('./data/')\n",
    "    train_tar.close()\n",
    "\n",
    "if not os.path.exists(test_file):\n",
    "    print('Downloading test.tar')\n",
    "    gdown.download(test_url, test_file)\n",
    "    test_tar = tarfile.open(test_file)\n",
    "    test_tar.extractall('./data/')\n",
    "    test_tar.close()\n",
    "\n",
    "if not os.path.exists(eurosat_file):\n",
    "    print('Downloading EuroSAT_RGB.zip')\n",
    "    response = urllib.request.urlretrieve(eurosat_url, eurosat_file)\n",
    "    eurosat_zip = zipfile.ZipFile(eurosat_file)\n",
    "    eurosat_zip.extractall('./data/eurosat')\n",
    "    eurosat_zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# If you encounter some issues regarding cuda device, e.g., \"RuntimeError: CUDA Out of memory error\",\n",
    "# try to switch the device to cpu by using the following code\n",
    "\n",
    "# device = torch.device('cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Size\n",
    "image_size = 32\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 100\n",
    "num_workers = 1\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.001\n",
    "\n",
    "# Momentum\n",
    "momentum = 0.9\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 30\n",
    "\n",
    "# Weight decay\n",
    "weight_decay=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet18 = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model_resnet34 = resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "model_resnet50 = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model_resnet101 = resnet101(weights=ResNet101_Weights.DEFAULT)\n",
    "model_resnet152 = resnet152(weights=ResNet152_Weights.DEFAULT)\n",
    "\n",
    "model_vgg11 = vgg11(weights=VGG11_Weights.DEFAULT)\n",
    "model_vgg13 = vgg13(weights=VGG13_Weights.DEFAULT)\n",
    "model_vgg16 = vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "model_vgg19 = vgg19(weights=VGG19_Weights.DEFAULT)\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root='./data/train',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(\n",
    "    root='./data/test',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    ")\n",
    "\n",
    "validation_dataset = torchvision.datasets.ImageFolder(\n",
    "    root='./data/val',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "dataloader_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "dataloader_validation = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(trained_model):\n",
    "    # Create Models Folder\n",
    "    if not os.path.exists('./models'):\n",
    "        print('Creating models directory')\n",
    "        os.mkdir('./models')\n",
    "\n",
    "    # Save the model\n",
    "    if not os.path.exists(f'./models/{trained_model.name}.pth'):\n",
    "        print(f'Saving Model {trained_model.name}')\n",
    "        torch.save(trained_model, f'./models/{trained_model.name}.pth')\n",
    "\n",
    "def load_model(model_name):\n",
    "    if not os.path.exists(f'./models/{model_name}.pth'):\n",
    "        print(f'Cannot Load {model_name}')\n",
    "        return None\n",
    "    print(f'Loading Model {model_name}')\n",
    "    model = torch.load(f'.models/{model_name}.pth')\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the used model\n",
    "model = model_resnet18\n",
    "model.name = \"resnet18\"     # Set name for saving\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr, momentum)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, criterion, device):\n",
    "\n",
    "    model.eval() \n",
    "    # valid_running_loss = 0.0\n",
    "    valid_running_correct = 0\n",
    "    counter = 0\n",
    "    num_images = 0.0 # used to accumulate number of images\n",
    "    test_acc = 0\n",
    "    \n",
    "    #with torch.no_grad():\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        counter += 1\n",
    "        \n",
    "        image, labels = data\n",
    "        image = image.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass.\n",
    "        outputs = model(image)\n",
    "        # Calculate the loss.\n",
    "        # loss = criterion(outputs, labels)\n",
    "        # valid_running_loss += loss.item()\n",
    "        # Calculate the accuracy.\n",
    "        #preds = outputs.argmax(dim=1)\n",
    "        preds = torch.max(outputs, 1).indices\n",
    "        test_acc += int(torch.sum(preds == labels))\n",
    "        \n",
    "        #valid_running_correct += preds.eq(labels).sum()\n",
    "        valid_running_correct += (preds == labels).sum().item()\n",
    "        num_images += len(labels)\n",
    "        \n",
    "    # Loss and accuracy for the complete epoch.\n",
    "    # epoch_loss = valid_running_loss / counter\n",
    "    print(\"Number of correct predictions: \", valid_running_correct)\n",
    "\n",
    "    epoch_acc = test_acc / num_images\n",
    "    return epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader_train, criterion, optimizer, num_epochs, device):\n",
    "    model.to(device)\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "\n",
    "    # Start the training.\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using CUDA\")\n",
    "\n",
    "    print('Training')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_running_loss = 0.0\n",
    "        train_running_correct = 0\n",
    "        counter = 0\n",
    "        num_images = 0.0 # used to accumulate number of images\n",
    "        for i, data in enumerate(dataloader_train,0):\n",
    "            counter += 1\n",
    "            image, labels = data\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass.\n",
    "            outputs = model(image)\n",
    "            # Calculate the loss.\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_running_loss += loss.item()\n",
    "            # Calculate the accuracy.\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            train_running_correct += (preds == labels).sum().item()\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            # Update the weights.\n",
    "            optimizer.step()    # Output training \n",
    "            num_images += len(image)\n",
    "            if counter % 100 == 0:\n",
    "                print(f'Epoch: {epoch+1}/{num_epochs}, Step: {counter}/{len(dataloader_train)}, Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "        # Validation\n",
    "        valid_epoch_acc = evaluate(model, dataloader_validation, criterion, device)\n",
    "        \n",
    "\n",
    "        lg.debug(f\"counter: {counter}, len(train_dataset): {len(train_dataset)}\")\n",
    "        lg.debug(f\"train_running_loss: {train_running_loss}, train_running_correct: {train_running_correct}\")\n",
    "        lg.debug(f\"Loss.item: {loss.item()}\")\n",
    "        lg.debug(f\"Loss: {loss}\")\n",
    "        \n",
    "        train_epoch_loss = train_running_loss / counter\n",
    "        train_loss.append(train_epoch_loss)\n",
    "        # valid_loss.append(valid_epoch_loss)\n",
    "        train_epoch_acc = train_running_correct/len(train_dataset)\n",
    "        train_acc.append(train_epoch_acc )\n",
    "\n",
    "        print('Epoch: %d/%d, Training accuracy: %f, loss: %f, validation accuracy: %f' % (epoch+1, num_epochs, train_epoch_acc, loss, valid_epoch_acc))\n",
    "\n",
    "        # valid_acc.append(valid_epoch_acc)\n",
    "        # print(f\"Training loss mean: {train_epoch_loss :.3f}, training acc: {train_epoch_acc:.3f}\")\n",
    "        # print(f\"Validation acc: {valid_epoch_acc:.3f}\")\n",
    "        print('-'*50)\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Training\n",
      "Epoch: 1/1, Step: 100/384, Loss: 0.3665\n",
      "Epoch: 1/1, Step: 200/384, Loss: 0.3072\n",
      "Epoch: 1/1, Step: 300/384, Loss: 0.2282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:counter: 384, len(train_dataset): 38400\n",
      "DEBUG:root:train_running_loss: 137.0183524787426, train_running_correct: 34245\n",
      "DEBUG:root:Loss.item: 0.346039742231369\n",
      "DEBUG:root:Loss: 0.346039742231369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct predictions:  117\n",
      "Epoch: 1/1, Training accuracy: 0.891797, loss: 0.346040, validation accuracy: 0.012188\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_model = train(model, dataloader_train, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate_loss, validate_acc = evaluate(trained_model, dataloader_validation, criterion, device)\n",
    "# print(f\"Validation loss: {validate_loss:.3f}, validation acc: {validate_acc:.3f}\")\n",
    "test_acc = evaluate(trained_model, dataloader_test, criterion, device)\n",
    "print(f\"test acc: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
    "def evaluate(model, data_loader, device):\n",
    "\n",
    "    model.eval() \n",
    "    print('Evaluate')\n",
    "    valid_running_correct = 0.0\n",
    "    num_images = 0.0 # used to accumulate number of images\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(data_loader, 0):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            # Calculate the accuracy.\n",
    "            #preds = outputs.argmax(dim=1)\n",
    "            preds = torch.max(outputs,1).indices\n",
    "            #valid_running_correct += preds.eq(labels).sum()\n",
    "            valid_running_correct += int(torch.sum(preds == labels))\n",
    "            num_images += len(labels)\n",
    "        \n",
    "        # accuracy for the complete epoch.\n",
    "        acc = valid_running_correct / num_images\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
    "def train(model, dataloader_train, dataloader_validation, criterion, optimizer, num_epochs, device):\n",
    "    model.to(device)\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "\n",
    "    # Start the training.\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Using CUDA\")\n",
    "\n",
    "    print('Training')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_running_loss = 0.0 # loss\n",
    "        train_running_correct = 0.0 # accuracy\n",
    "        num_images = 0.0 # used to accumulate number of images\n",
    "\n",
    "        for i, data  in enumerate(dataloader_train,0):\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Forward pass.\n",
    "            outputs = model(images)\n",
    "            # Calculate the loss.\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_running_loss += loss.item()\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            # Update the weights.\n",
    "            optimizer.step() # Output training \n",
    "\n",
    "            # Calculate the accuracy.\n",
    "            num_images += images.size(0)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            train_running_correct += (preds == labels).sum().item()\n",
    "\n",
    "        acc = train_running_correct / num_images      \n",
    "        acc_eval = evaluate(model, dataloader_validation, device)  \n",
    "        print('epoch: %d, accuracy: %f, loss: %f, validation accuracy: %f' % (epoch, acc, loss, acc_eval))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWWW\n",
    "trained_model = train(model, dataloader_train, dataloader_validation, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 100 images from EuroSAT dataset\n",
    "\n",
    "if not os.path.exists('./data/eurosat_selected'):\n",
    "    print('Creating data directory')\n",
    "    os.mkdir('./data/eurosat_selected')\n",
    "\n",
    "if not os.path.exists('./data/eurosat_training'):\n",
    "    print('Creating training directory')\n",
    "    os.mkdir('./data/eurosat_training')\n",
    "\n",
    "# Load the EuroSAT Categories\n",
    "eurosat_categories = [name for name in os.listdir('./data/eurosat/EuroSAT_RGB/') if os.path.isdir(os.path.join('./data/eurosat/EuroSAT_RGB/', name))]\n",
    "# Randomly select 5 categories\n",
    "print(f\"Selecting 5 categories from {eurosat_categories} categories\")\n",
    "selected_categories = np.random.choice(eurosat_categories, 5, replace=False)\n",
    "print(f\"Selected categories: {selected_categories}\")\n",
    "\n",
    "selected_images = []\n",
    "training_images = []\n",
    "\n",
    "# From each directory, randomly select 20 images\n",
    "for category in selected_categories:\n",
    "    images = os.listdir(os.path.join('./data/eurosat/EuroSAT_RGB/', category))\n",
    "    selected = random.sample(images, 20)\n",
    "    selected_images.extend([(category, image) for image in selected])\n",
    "    print(f\"Selected {selected} from {category}\")\n",
    "    # Copy selected images to the selected directory\n",
    "    for image in selected:\n",
    "        shutil.copyfile(os.path.join('./data/eurosat/EuroSAT_RGB', category, image), os.path.join('./data/eurosat_selected', image))\n",
    "\n",
    "# From these 100 images, randomly select 5 images from each category for the training set\n",
    "for category in selected_categories:\n",
    "    category_images = [image for (cat, image) in selected_images if cat == category]\n",
    "    training = random.sample(category_images, 5)\n",
    "    training_images.extend(training)\n",
    "    print(f\"Selected {training} for training\")\n",
    "\n",
    "    # Copy training images to the training directory\n",
    "    for image in training:\n",
    "        shutil.copyfile(os.path.join('./data/eurosat_selected', image), os.path.join('./data/eurosat_training', image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
